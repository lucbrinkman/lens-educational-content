---
slug: introduction
title: Introduction
discussion-note: "[[../../Lens Academy/Course Introduction Discussion|Course Introduction Discussion]]"
---
# Text
content::
We begin by examining the potential of AI and the risks and opportunities that the characteristics of this technology present to humanity{>>CGL > This does not feel like an introduction to me. It feels like the first module of content. 

I would expect an introduction to explain why we built this course and what we expect the students to be able to do at the end of the course. It might also include a basic introduction to the platform and how the weekly meetings are expected to proceed. <<}. 


# Learning Objective:
[[../Learning Outcomes/Unknown intro outcome 1|Unknown intro outcome 1]]






[[../Sections/Wikipedia Existential Risk]]

# Learning Objective:
[[../Learning Outcomes/Objections L1 - Realize objections and rebuttals exist|Objections L1 - Realize objections and rebuttals exist]]

# Article: Four Background Claims (Optional)
source:: [[../articles/nate-soares-four-background-claims]]
optional:: true

## Text
content::
This text explains exactly how the emergence of AI smarter than humans could become an event with enormous stakes, and why, in the author's opinion, there is already meaningful work being done today that increases the chance of a positive outcome. The author identifies four key premises that underpin his entire perspective on the prospects of AI.

## Article-excerpt

# Article: Worst-Case Thinking (Optional)
source:: [[../articles/buck-worst-case-thinking-in-ai-alignment]]
optional:: true

## Text
content::
In discussions of AI safety, people often propose the assumption that something will go as badly as possible. Different people may do this for different reasons; in this essay, the author reviews some of the most common reasons and writes about how this difference might manifest itself and what it means.

## Article-excerpt

